{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 訓練パイプライン\n",
    "\n",
    "- パイプライン\n",
    "    - 様々なモジュールを順番に組み合わせて実行すること\n",
    "    - 特徴洗濯、前処理、ランダムフォレスト、クラスタリングなどなど\n",
    "\n",
    "- 今回は入力データ点から上位k個の特徴量を洗濯し、ERT分類器を使って分類する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Predicted output：\n [0 2 2 0 2 0 2 1 0 1 1 2 1 0 2 2 1 0 0 1 0 2 1 1 2 2 0 0 1 2 1 2 1 0 2 2 1\n 1 2 2 2 0 1 2 2 1 1 2 1 0 1 2 2 2 2 0 2 2 0 2 2 0 1 0 2 1 1 1 1 2 0 0 0 2\n 0 0 1 2 2 0 0 2 2 2 2 0 0 0 2 2 2 1 2 0 2 0 2 2 0 0 1 1 1 1 2 2 2 2 0 1 1\n 0 2 1 1 0 1 1 1 1 0 0 0 1 2 0 0 0 2 1 2 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 2 0\n 2 2]\n\nScore: 0.9133333333333333\n"
    }
   ],
   "source": [
    "from sklearn.datasets import samples_generator\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# 25次元の特徴ベクトルで表現される150個のラベル付き教師データを生成する\n",
    "X, y = samples_generator.make_classification(n_samples=150,\n",
    "                n_features=25, n_classes=3, n_informative=6,\n",
    "                n_redundant=0, random_state=7)\n",
    "\n",
    "# 上位k（=9）個の特徴量を選択する\n",
    "k_best_selector = SelectKBest(f_regression, k=9)\n",
    "\n",
    "# 推定器が60個で最大深さ4のERT分類器を作る\n",
    "classifier = ExtraTreesClassifier(n_estimators=60, max_depth=4)\n",
    "\n",
    "# パイプラインを作成する\n",
    "# k_best_selectorを'selector'、classifierを'erf'という名前でブロックを作成する\n",
    "processor_pipeline = Pipeline([('selector', k_best_selector), ('erf', classifier)])\n",
    "\n",
    "# パイプラインに指定したブロックには引数を渡せる\n",
    "# ブロック名__引数名\n",
    "processor_pipeline.set_params(selector__k=7, erf__n_estimators=30)\n",
    "\n",
    "# 作ったパイプラインで訓練する\n",
    "processor_pipeline.fit(X, y)\n",
    "\n",
    "# 入力値Xに対して推論する\n",
    "output = processor_pipeline.predict(X)\n",
    "print(\"Predicted output：\\n\", output)\n",
    "\n",
    "# 処理の分類性能\n",
    "print(\"\\nScore:\", processor_pipeline.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "25\n[False False False False  True False False  True  True False False False\n  True False  True False False  True False False False False  True False\n False]\n\nIndices of selected features: 4, 7, 8, 12, 14, 17, 22\n"
    }
   ],
   "source": [
    "# 特徴抽出の状態を取得する\n",
    "status = processor_pipeline.named_steps['selector'].get_support()\n",
    "\n",
    "# statusは25個\n",
    "print(len(status))\n",
    "\n",
    "# Trueが有効と判断された特徴量\n",
    "print(status)\n",
    "\n",
    "# 有効な特徴量のインデックス番号を表示するためにごにょごにょする\n",
    "selected = [i for i, x in enumerate(status) if x]\n",
    "print(\"\\nIndices of selected features:\", ', '.join([str(x) for x in selected]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}